{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /anaconda/envs/jupyter_env/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: gremlinpython in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gremlinpython) (0.6.1)\n",
      "Requirement already satisfied: aenum<4.0.0,>=1.4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gremlinpython) (3.1.12)\n",
      "Requirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gremlinpython) (3.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gremlinpython) (1.5.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (4.0.2)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from isodate<1.0.0,>=0.6.0->gremlinpython) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp<=3.8.1,>=3.8.0->gremlinpython) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gremlinpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from itertools import combinations\n",
    "\n",
    "# Graph related imports\n",
    "import nest_asyncio\n",
    "from gremlin_python.driver import client, serializer\n",
    "\n",
    "# Azure imports\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary to avoid \"RuntimeError: Cannot run the event loop while another loop is running\"\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "gremlin_client = client.Client('wss://leomathesis-cosmos-gremlin.gremlin.cosmos.azure.com:443/', 'g',\n",
    "                               username=\"/dbs/mathesisleo-database/colls/year-graph-2010\",\n",
    "                               password=\"<<password>>\",\n",
    "                               message_serializer=serializer.GraphSONSerializersV2d0()\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertex(label, id, type, prop_dict={}):\n",
    "    prop_dict['object_id'] = id\n",
    "    prop_dict['id'] = f\"{type}_{id}\"\n",
    "    prop_dict['type'] = type\n",
    "    gremlin_query = f'g.addV(\"{label}\")'\n",
    "    for key, value in prop_dict.items():\n",
    "        if isinstance(value, list):\n",
    "            for value_entry in value:\n",
    "                gremlin_query += f'.property(\"{key}\", \"{value_entry}\")'\n",
    "        else:\n",
    "            gremlin_query += f'.property(\"{key}\", \"{value}\")'\n",
    "    for i in range(500):\n",
    "        if gremlin_client.available_pool_size > 0:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "    gremlin_client.submit_async(gremlin_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge(label, from_id, to_id, prop_dict={}):\n",
    "    gremlin_query = f'g.V(\"{from_id}\").as(\"a\").V(\"{to_id}\").as(\"b\").addE(\"{label}\").from(\"a\").to(\"b\")'\n",
    "    for key, value in prop_dict.items():\n",
    "        if type(value) == int or type(value) == float:\n",
    "            gremlin_query += f'.property(\"{key}\", {value})'\n",
    "        else:\n",
    "            gremlin_query += f'.property(\"{key}\", \"{value}\")'\n",
    "    for i in range(50):\n",
    "        if gremlin_client.available_pool_size > 0:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "    gremlin_client.submit_async(gremlin_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gremlin_python.driver.resultset.ResultSet at 0x7fe61f039600>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gremlin_client.submit(\"g.V().drop()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "last_cnt = 0\n",
    "for i in range(200):\n",
    "    callback = gremlin_client.submit_async(\"g.V().count()\")\n",
    "    cnt = callback.result().all().result()[0]\n",
    "    print(cnt)\n",
    "    if cnt == 0:\n",
    "        break\n",
    "    else:\n",
    "        if last_cnt == cnt:\n",
    "            gremlin_client.submit(\"g.V().drop()\")\n",
    "            pass\n",
    "        time.sleep(10)\n",
    "        last_cnt = cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding vertices for persons and parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Message: rslex failed, falling back to clex.\n",
      "Payload: {\"pid\": 44075, \"source\": \"azureml.dataprep\", \"version\": \"4.8.4\", \"trace\": \"azureml|data|tabular_dataset.py, line 169 in function <lambda>.\\nazureml|data|dataset_error_handling.py, line 106 in function _try_execute.\\nazureml|data|tabular_dataset.py, line 169 in function to_pandas_dataframe.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.15.2\"}\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
     ]
    }
   ],
   "source": [
    "subscription_id = '<<subscription_id>>'\n",
    "resource_group = 'rg-leore-001'\n",
    "workspace_name = 'leomathesisML'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='db_politician_data_asset')\n",
    "df_politicians = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_translate = {'CVP': 'Die Mitte',\n",
    "                   'BDP': 'Die Mitte',\n",
    "                   'GP': 'Gr√ºne',\n",
    "                   'FPS': 'APS',\n",
    "                   'LdU': 'DaP/LdU'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politicians['party'] = df_politicians['party'].map(party_translate).fillna(df_politicians['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SP',\n",
       " 'Die Mitte',\n",
       " 'FDP',\n",
       " 'SVP',\n",
       " 'SD',\n",
       " 'DaP/LdU',\n",
       " 'Gr√ºne',\n",
       " 'APS',\n",
       " 'EVP',\n",
       " 'FraP',\n",
       " 'GLP',\n",
       " 'EDU',\n",
       " 'SaS',\n",
       " 'parteilos',\n",
       " 'AL',\n",
       " 'CSP']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parties = list(df_politicians['party'].unique())\n",
    "parties.remove(None)\n",
    "parties.remove('unknown')\n",
    "parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, party in enumerate(parties):\n",
    "    add_vertex(label=party, id=idx, type='party', prop_dict={'name': party})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = df_politicians[['person_id', 'first_name', 'last_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_politician(df_row):\n",
    "    full_name = f\"{df_row['first_name']} {df_row['last_name']}\"\n",
    "    prop_dict = {'first_name': df_row['first_name'], \n",
    "                 'last_name': df_row['last_name'], \n",
    "                 'person_id': df_row['person_id']}\n",
    "    add_vertex(label=full_name, \n",
    "               id=df_row['person_id'], \n",
    "               type='politician', \n",
    "               prop_dict=prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = politicians.apply(add_politician, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_politician_party(df_row):\n",
    "    if df_row['party'] not in (None, 'unknown'):\n",
    "        prop_dict = {'valid_from': df_row['valid_from'], \n",
    "                     'valid_to': df_row['valid_to'],\n",
    "                     'council': df_row['council']}\n",
    "        callback = gremlin_client.submit_async(f'g.V().hasLabel(\"{df_row[\"party\"]}\").values(\"id\")')\n",
    "        party_id = callback.result().all().result()[0]\n",
    "        add_edge(label='is_member_of', \n",
    "                 from_id=f\"politician_{df_row['person_id']}\", \n",
    "                 to_id=party_id,\n",
    "                 prop_dict=prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_politicians.apply(add_politician_party, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding vertices for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pickle.load(open('../data/topics_manual-finetune_2010.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_nr, topic in topics.items():\n",
    "    if topic_nr >= 0:\n",
    "        topic_name = str(topic_nr)\n",
    "        for i in range(4):\n",
    "            topic_name += \"_\" + topic[i][0]\n",
    "        prop_dict = {'topic_id': topic_nr,\n",
    "                     'topic_name': topic_name,\n",
    "                     'topic_words': [i[0] for i in topic]}\n",
    "        add_vertex(label=topic_name, \n",
    "                   id=topic_nr,\n",
    "                   type='topic',\n",
    "                   prop_dict=prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding edges between topics and politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.read_pickle('../data/df_topic_manual-finetune_2010.pkl')\n",
    "sent_df = pd.read_pickle('../data/df_sent_2010.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = topic_df.merge(sent_df, how='left', on='window_id')\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = df[(df['Topic'] >= 0) & (df['person_id'].notnull())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 169156 entries, 135 to 673959\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   window_id                169156 non-null  int64         \n",
      " 1   paragraph_id             169156 non-null  int64         \n",
      " 2   item_of_business         169156 non-null  object        \n",
      " 3   person_id                169156 non-null  object        \n",
      " 4   first_name               169156 non-null  object        \n",
      " 5   last_name                169156 non-null  object        \n",
      " 6   council                  169156 non-null  object        \n",
      " 7   party                    169156 non-null  object        \n",
      " 8   in_admin_role            169156 non-null  bool          \n",
      " 9   text                     169156 non-null  object        \n",
      " 10  date                     169156 non-null  datetime64[ns]\n",
      " 11  session_title            169156 non-null  object        \n",
      " 12  session_id               169156 non-null  int64         \n",
      " 13  tokens                   169156 non-null  object        \n",
      " 14  sentences_window_x       169156 non-null  object        \n",
      " 15  Document                 169156 non-null  object        \n",
      " 16  Topic                    169156 non-null  int64         \n",
      " 17  Name                     169156 non-null  object        \n",
      " 18  Top_n_words              169156 non-null  object        \n",
      " 19  Probability              169156 non-null  float64       \n",
      " 20  Representative_document  169156 non-null  bool          \n",
      " 21  sentences_window_y       169156 non-null  object        \n",
      " 22  sentiment                169156 non-null  float64       \n",
      " 23  year                     169156 non-null  int64         \n",
      "dtypes: bool(2), datetime64[ns](1), float64(2), int64(5), object(14)\n",
      "memory usage: 30.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_graph.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {}\n",
    "for year in df_graph['year'].unique():\n",
    "    prob_year_key = f'Probability_{year}'\n",
    "    sent_year_key = f'sentiment_{year}'\n",
    "    agg_dict[prob_year_key] = 'sum'\n",
    "    agg_dict[sent_year_key] = 'mean'\n",
    "    df_graph[prob_year_key] = df_graph[df_graph['year'] == year]['Probability']\n",
    "    df_graph[sent_year_key] = df_graph[df_graph['year'] == year]['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 169156 entries, 135 to 673959\n",
      "Data columns (total 52 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   window_id                169156 non-null  int64         \n",
      " 1   paragraph_id             169156 non-null  int64         \n",
      " 2   item_of_business         169156 non-null  object        \n",
      " 3   person_id                169156 non-null  object        \n",
      " 4   first_name               169156 non-null  object        \n",
      " 5   last_name                169156 non-null  object        \n",
      " 6   council                  169156 non-null  object        \n",
      " 7   party                    169156 non-null  object        \n",
      " 8   in_admin_role            169156 non-null  bool          \n",
      " 9   text                     169156 non-null  object        \n",
      " 10  date                     169156 non-null  datetime64[ns]\n",
      " 11  session_title            169156 non-null  object        \n",
      " 12  session_id               169156 non-null  int64         \n",
      " 13  tokens                   169156 non-null  object        \n",
      " 14  sentences_window_x       169156 non-null  object        \n",
      " 15  Document                 169156 non-null  object        \n",
      " 16  Topic                    169156 non-null  int64         \n",
      " 17  Name                     169156 non-null  object        \n",
      " 18  Top_n_words              169156 non-null  object        \n",
      " 19  Probability              169156 non-null  float64       \n",
      " 20  Representative_document  169156 non-null  bool          \n",
      " 21  sentences_window_y       169156 non-null  object        \n",
      " 22  sentiment                169156 non-null  float64       \n",
      " 23  year                     169156 non-null  int64         \n",
      " 24  Probability_2010         10182 non-null   float64       \n",
      " 25  sentiment_2010           10182 non-null   float64       \n",
      " 26  Probability_2011         11079 non-null   float64       \n",
      " 27  sentiment_2011           11079 non-null   float64       \n",
      " 28  Probability_2012         10977 non-null   float64       \n",
      " 29  sentiment_2012           10977 non-null   float64       \n",
      " 30  Probability_2013         11899 non-null   float64       \n",
      " 31  sentiment_2013           11899 non-null   float64       \n",
      " 32  Probability_2014         12650 non-null   float64       \n",
      " 33  sentiment_2014           12650 non-null   float64       \n",
      " 34  Probability_2015         11849 non-null   float64       \n",
      " 35  sentiment_2015           11849 non-null   float64       \n",
      " 36  Probability_2016         13753 non-null   float64       \n",
      " 37  sentiment_2016           13753 non-null   float64       \n",
      " 38  Probability_2017         11387 non-null   float64       \n",
      " 39  sentiment_2017           11387 non-null   float64       \n",
      " 40  Probability_2018         14520 non-null   float64       \n",
      " 41  sentiment_2018           14520 non-null   float64       \n",
      " 42  Probability_2019         13322 non-null   float64       \n",
      " 43  sentiment_2019           13322 non-null   float64       \n",
      " 44  Probability_2020         14256 non-null   float64       \n",
      " 45  sentiment_2020           14256 non-null   float64       \n",
      " 46  Probability_2021         14350 non-null   float64       \n",
      " 47  sentiment_2021           14350 non-null   float64       \n",
      " 48  Probability_2022         15280 non-null   float64       \n",
      " 49  sentiment_2022           15280 non-null   float64       \n",
      " 50  Probability_2023         3652 non-null    float64       \n",
      " 51  sentiment_2023           3652 non-null    float64       \n",
      "dtypes: bool(2), datetime64[ns](1), float64(30), int64(5), object(14)\n",
      "memory usage: 66.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_graph.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph['party'] = df_graph['party'].map(party_translate).fillna(df_graph['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict['Probability'] = 'sum'\n",
    "agg_dict['sentiment'] = 'mean'\n",
    "df_person_topic_grouped = df_graph.groupby(['person_id', 'Topic'], as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Probability_2010</th>\n",
       "      <th>sentiment_2010</th>\n",
       "      <th>Probability_2011</th>\n",
       "      <th>sentiment_2011</th>\n",
       "      <th>Probability_2012</th>\n",
       "      <th>sentiment_2012</th>\n",
       "      <th>Probability_2013</th>\n",
       "      <th>sentiment_2013</th>\n",
       "      <th>...</th>\n",
       "      <th>Probability_2020</th>\n",
       "      <th>sentiment_2020</th>\n",
       "      <th>Probability_2021</th>\n",
       "      <th>sentiment_2021</th>\n",
       "      <th>Probability_2022</th>\n",
       "      <th>sentiment_2022</th>\n",
       "      <th>Probability_2023</th>\n",
       "      <th>sentiment_2023</th>\n",
       "      <th>Probability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.601759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.660662</td>\n",
       "      <td>-0.211594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.031365</td>\n",
       "      <td>-0.380621</td>\n",
       "      <td>6.462950</td>\n",
       "      <td>-0.152682</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>-0.294839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.599387</td>\n",
       "      <td>-0.240894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14988</td>\n",
       "      <td>2</td>\n",
       "      <td>2.769931</td>\n",
       "      <td>-0.31405</td>\n",
       "      <td>0.881466</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>31.339367</td>\n",
       "      <td>0.208662</td>\n",
       "      <td>26.030048</td>\n",
       "      <td>0.144966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.200253</td>\n",
       "      <td>0.032078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.357199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.202943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14988</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731819</td>\n",
       "      <td>-0.042855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.546479</td>\n",
       "      <td>-0.331252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12288</th>\n",
       "      <td>9060</td>\n",
       "      <td>213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.966395</td>\n",
       "      <td>0.070897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289</th>\n",
       "      <td>9060</td>\n",
       "      <td>218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.187772</td>\n",
       "      <td>-0.021847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.187772</td>\n",
       "      <td>-0.021847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12290</th>\n",
       "      <td>9060</td>\n",
       "      <td>233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.997832</td>\n",
       "      <td>-0.726120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>9060</td>\n",
       "      <td>239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.834733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12292</th>\n",
       "      <td>9060</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.993585</td>\n",
       "      <td>0.157836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.993585</td>\n",
       "      <td>0.157836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12293 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_id  Topic  Probability_2010  sentiment_2010  Probability_2011  \\\n",
       "0         14988      0          0.000000             NaN          0.000000   \n",
       "1         14988      1          0.000000             NaN          9.031365   \n",
       "2         14988      2          2.769931        -0.31405          0.881466   \n",
       "3         14988      3          0.000000             NaN          8.000000   \n",
       "4         14988      4          0.000000             NaN          0.731819   \n",
       "...         ...    ...               ...             ...               ...   \n",
       "12288      9060    213          0.000000             NaN          0.000000   \n",
       "12289      9060    218          0.000000             NaN          0.000000   \n",
       "12290      9060    233          0.000000             NaN          0.000000   \n",
       "12291      9060    239          0.000000             NaN          0.000000   \n",
       "12292      9060    250          0.000000             NaN          0.000000   \n",
       "\n",
       "       sentiment_2011  Probability_2012  sentiment_2012  Probability_2013  \\\n",
       "0                 NaN          0.000000             NaN          2.000000   \n",
       "1           -0.380621          6.462950       -0.152682         23.000000   \n",
       "2            0.028439         31.339367        0.208662         26.030048   \n",
       "3            0.357199          0.000000             NaN          0.000000   \n",
       "4           -0.042855          0.000000             NaN          0.000000   \n",
       "...               ...               ...             ...               ...   \n",
       "12288             NaN          0.000000             NaN          0.000000   \n",
       "12289             NaN          0.000000             NaN          0.000000   \n",
       "12290             NaN          0.000000             NaN          0.000000   \n",
       "12291             NaN          0.000000             NaN          0.000000   \n",
       "12292             NaN          0.000000             NaN          0.000000   \n",
       "\n",
       "       sentiment_2013  ...  Probability_2020  sentiment_2020  \\\n",
       "0           -0.601759  ...          0.000000             NaN   \n",
       "1           -0.294839  ...          0.000000             NaN   \n",
       "2            0.144966  ...          0.000000             NaN   \n",
       "3                 NaN  ...          0.000000             NaN   \n",
       "4                 NaN  ...          0.000000             NaN   \n",
       "...               ...  ...               ...             ...   \n",
       "12288             NaN  ...          0.000000             NaN   \n",
       "12289             NaN  ...          0.000000             NaN   \n",
       "12290             NaN  ...          0.000000             NaN   \n",
       "12291             NaN  ...          0.000000             NaN   \n",
       "12292             NaN  ...          7.993585        0.157836   \n",
       "\n",
       "       Probability_2021  sentiment_2021  Probability_2022  sentiment_2022  \\\n",
       "0                   0.0             NaN          0.000000             NaN   \n",
       "1                   0.0             NaN          0.000000             NaN   \n",
       "2                   0.0             NaN          0.000000             NaN   \n",
       "3                   0.0             NaN          0.000000             NaN   \n",
       "4                   0.0             NaN          0.000000             NaN   \n",
       "...                 ...             ...               ...             ...   \n",
       "12288               0.0             NaN          0.000000             NaN   \n",
       "12289               0.0             NaN          9.187772       -0.021847   \n",
       "12290               0.0             NaN          0.000000             NaN   \n",
       "12291               0.0             NaN          0.000000             NaN   \n",
       "12292               0.0             NaN          0.000000             NaN   \n",
       "\n",
       "       Probability_2023  sentiment_2023  Probability  sentiment  \n",
       "0                   0.0             NaN     9.660662  -0.211594  \n",
       "1                   0.0             NaN    96.599387  -0.240894  \n",
       "2                   0.0             NaN   181.200253   0.032078  \n",
       "3                   0.0             NaN    19.000000   0.202943  \n",
       "4                   0.0             NaN     1.546479  -0.331252  \n",
       "...                 ...             ...          ...        ...  \n",
       "12288               0.0             NaN     8.966395   0.070897  \n",
       "12289               0.0             NaN     9.187772  -0.021847  \n",
       "12290               0.0             NaN     2.997832  -0.726120  \n",
       "12291               0.0             NaN     9.000000  -0.834733  \n",
       "12292               0.0             NaN     7.993585   0.157836  \n",
       "\n",
       "[12293 rows x 32 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_person_topic_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability_2010\n",
      "sentiment_2010\n",
      "Probability_2011\n",
      "sentiment_2011\n",
      "Probability_2012\n",
      "sentiment_2012\n",
      "Probability_2013\n",
      "sentiment_2013\n",
      "Probability_2014\n",
      "sentiment_2014\n",
      "Probability_2015\n",
      "sentiment_2015\n",
      "Probability_2016\n",
      "sentiment_2016\n",
      "Probability_2017\n",
      "sentiment_2017\n",
      "Probability_2018\n",
      "sentiment_2018\n",
      "Probability_2019\n",
      "sentiment_2019\n",
      "Probability_2020\n",
      "sentiment_2020\n",
      "Probability_2021\n",
      "sentiment_2021\n",
      "Probability_2022\n",
      "sentiment_2022\n",
      "Probability_2023\n",
      "sentiment_2023\n",
      "Probability\n",
      "sentiment\n"
     ]
    }
   ],
   "source": [
    "for col in agg_dict.keys():\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_politician_topic(df_row):\n",
    "    prop_dict = {'weight_total': df_row['Probability'] * 4,\n",
    "                 'sentiment_total': df_row['sentiment']}\n",
    "    for col in agg_dict.keys():\n",
    "        if col.startswith('Probability_'):\n",
    "            prop_dict[f\"weight_{col.split('_')[1]}\"] = df_row[col] * 4\n",
    "        elif col.startswith('sentiment_'):\n",
    "            prop_dict[f\"sentiment_{col.split('_')[1]}\"] = float(np.nan_to_num(df_row[col]))\n",
    "    add_edge(label='discusses', \n",
    "             from_id=f\"politician_{df_row['person_id']}\", \n",
    "             to_id=f\"topic_{df_row['Topic']}\",\n",
    "             prop_dict=prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12293/12293 [02:43<00:00, 75.11it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = df_person_topic_grouped.progress_apply(add_politician_topic, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_topic_grouped = df_graph[(df_graph['party'] != 'unknown') & (df_graph['party'].notnull())].groupby(['party', 'Topic'], as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Probability_2010</th>\n",
       "      <th>sentiment_2010</th>\n",
       "      <th>Probability_2011</th>\n",
       "      <th>sentiment_2011</th>\n",
       "      <th>Probability_2012</th>\n",
       "      <th>sentiment_2012</th>\n",
       "      <th>Probability_2013</th>\n",
       "      <th>sentiment_2013</th>\n",
       "      <th>...</th>\n",
       "      <th>Probability_2020</th>\n",
       "      <th>sentiment_2020</th>\n",
       "      <th>Probability_2021</th>\n",
       "      <th>sentiment_2021</th>\n",
       "      <th>Probability_2022</th>\n",
       "      <th>sentiment_2022</th>\n",
       "      <th>Probability_2023</th>\n",
       "      <th>sentiment_2023</th>\n",
       "      <th>Probability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>29.674695</td>\n",
       "      <td>-0.238971</td>\n",
       "      <td>34.040140</td>\n",
       "      <td>-0.486399</td>\n",
       "      <td>21.755519</td>\n",
       "      <td>-0.461124</td>\n",
       "      <td>14.953877</td>\n",
       "      <td>-0.532488</td>\n",
       "      <td>...</td>\n",
       "      <td>63.077538</td>\n",
       "      <td>-0.283283</td>\n",
       "      <td>52.609028</td>\n",
       "      <td>-0.216220</td>\n",
       "      <td>46.336336</td>\n",
       "      <td>-0.410074</td>\n",
       "      <td>9.735440</td>\n",
       "      <td>-0.243692</td>\n",
       "      <td>636.054410</td>\n",
       "      <td>-0.391647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-0.404518</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.740836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.556087</td>\n",
       "      <td>-0.194274</td>\n",
       "      <td>23.000920</td>\n",
       "      <td>-0.187283</td>\n",
       "      <td>85.640247</td>\n",
       "      <td>-0.120240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262.307944</td>\n",
       "      <td>-0.222302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.502974</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>17.171707</td>\n",
       "      <td>-0.332358</td>\n",
       "      <td>15.872681</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>17.450583</td>\n",
       "      <td>-0.034866</td>\n",
       "      <td>181.854870</td>\n",
       "      <td>-0.061487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>3</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.056570</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-0.317958</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.232998</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.243998</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.135072</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.137308</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.194526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.276022</td>\n",
       "      <td>0.070253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>27.384266</td>\n",
       "      <td>-0.168635</td>\n",
       "      <td>3.222739</td>\n",
       "      <td>-0.491469</td>\n",
       "      <td>5.128765</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>23.988941</td>\n",
       "      <td>-0.248426</td>\n",
       "      <td>...</td>\n",
       "      <td>43.971881</td>\n",
       "      <td>-0.168215</td>\n",
       "      <td>40.613542</td>\n",
       "      <td>-0.387522</td>\n",
       "      <td>32.314276</td>\n",
       "      <td>-0.264617</td>\n",
       "      <td>0.698360</td>\n",
       "      <td>-0.834019</td>\n",
       "      <td>483.960052</td>\n",
       "      <td>-0.251889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>parteilos</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.470289</td>\n",
       "      <td>-0.800510</td>\n",
       "      <td>1.780314</td>\n",
       "      <td>-0.967500</td>\n",
       "      <td>3.295349</td>\n",
       "      <td>-0.458486</td>\n",
       "      <td>3.308876</td>\n",
       "      <td>-0.900142</td>\n",
       "      <td>12.854829</td>\n",
       "      <td>-0.758137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>parteilos</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534259</td>\n",
       "      <td>-0.182488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534259</td>\n",
       "      <td>-0.182488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>parteilos</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.641944</td>\n",
       "      <td>-0.812061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.764906</td>\n",
       "      <td>-0.336162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.406850</td>\n",
       "      <td>-0.574112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>parteilos</td>\n",
       "      <td>189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069339</td>\n",
       "      <td>-0.843898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.391455</td>\n",
       "      <td>-0.910598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.460794</td>\n",
       "      <td>-0.877248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>parteilos</td>\n",
       "      <td>198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500971</td>\n",
       "      <td>-0.324177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500971</td>\n",
       "      <td>-0.324177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          party  Topic  Probability_2010  sentiment_2010  Probability_2011  \\\n",
       "0            AL      0         29.674695       -0.238971         34.040140   \n",
       "1            AL      1          0.000000             NaN          7.000000   \n",
       "2            AL      2          0.000000             NaN          0.000000   \n",
       "3            AL      3         36.000000        0.056570          8.000000   \n",
       "4            AL      4         27.384266       -0.168635          3.222739   \n",
       "...         ...    ...               ...             ...               ...   \n",
       "2119  parteilos    146          0.000000             NaN          0.000000   \n",
       "2120  parteilos    170          0.000000             NaN          0.000000   \n",
       "2121  parteilos    172          0.000000             NaN          0.000000   \n",
       "2122  parteilos    189          0.000000             NaN          0.000000   \n",
       "2123  parteilos    198          0.000000             NaN          0.000000   \n",
       "\n",
       "      sentiment_2011  Probability_2012  sentiment_2012  Probability_2013  \\\n",
       "0          -0.486399         21.755519       -0.461124         14.953877   \n",
       "1          -0.404518          6.000000       -0.740836          0.000000   \n",
       "2                NaN          0.000000             NaN          0.000000   \n",
       "3          -0.317958         35.000000        0.232998         10.000000   \n",
       "4          -0.491469          5.128765       -0.015500         23.988941   \n",
       "...              ...               ...             ...               ...   \n",
       "2119             NaN          0.000000             NaN          0.000000   \n",
       "2120             NaN          0.000000             NaN          0.000000   \n",
       "2121             NaN          0.000000             NaN          0.000000   \n",
       "2122             NaN          0.000000             NaN          0.000000   \n",
       "2123             NaN          0.000000             NaN          0.000000   \n",
       "\n",
       "      sentiment_2013  ...  Probability_2020  sentiment_2020  Probability_2021  \\\n",
       "0          -0.532488  ...         63.077538       -0.283283         52.609028   \n",
       "1                NaN  ...         46.556087       -0.194274         23.000920   \n",
       "2                NaN  ...         29.502974        0.017799         17.171707   \n",
       "3           0.243998  ...         17.000000        0.135072         14.000000   \n",
       "4          -0.248426  ...         43.971881       -0.168215         40.613542   \n",
       "...              ...  ...               ...             ...               ...   \n",
       "2119             NaN  ...          4.470289       -0.800510          1.780314   \n",
       "2120             NaN  ...          0.534259       -0.182488          0.000000   \n",
       "2121             NaN  ...          7.641944       -0.812061          0.000000   \n",
       "2122             NaN  ...          1.069339       -0.843898          0.000000   \n",
       "2123             NaN  ...          0.000000             NaN          0.000000   \n",
       "\n",
       "      sentiment_2021  Probability_2022  sentiment_2022  Probability_2023  \\\n",
       "0          -0.216220         46.336336       -0.410074          9.735440   \n",
       "1          -0.187283         85.640247       -0.120240          0.000000   \n",
       "2          -0.332358         15.872681        0.032907         17.450583   \n",
       "3          -0.137308         11.000000        0.194526          0.000000   \n",
       "4          -0.387522         32.314276       -0.264617          0.698360   \n",
       "...              ...               ...             ...               ...   \n",
       "2119       -0.967500          3.295349       -0.458486          3.308876   \n",
       "2120             NaN          0.000000             NaN          0.000000   \n",
       "2121             NaN          7.764906       -0.336162          0.000000   \n",
       "2122             NaN          1.391455       -0.910598          0.000000   \n",
       "2123             NaN          7.500971       -0.324177          0.000000   \n",
       "\n",
       "      sentiment_2023  Probability  sentiment  \n",
       "0          -0.243692   636.054410  -0.391647  \n",
       "1                NaN   262.307944  -0.222302  \n",
       "2          -0.034866   181.854870  -0.061487  \n",
       "3                NaN   255.276022   0.070253  \n",
       "4          -0.834019   483.960052  -0.251889  \n",
       "...              ...          ...        ...  \n",
       "2119       -0.900142    12.854829  -0.758137  \n",
       "2120             NaN     0.534259  -0.182488  \n",
       "2121             NaN    15.406850  -0.574112  \n",
       "2122             NaN     2.460794  -0.877248  \n",
       "2123             NaN     7.500971  -0.324177  \n",
       "\n",
       "[2124 rows x 32 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_party_topic_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_party_topic(df_row):\n",
    "    prop_dict = {'weight_total': df_row['Probability'] * 4,\n",
    "                 'sentiment_total': df_row['sentiment']}\n",
    "    for col in agg_dict.keys():\n",
    "        if col.startswith('Probability_'):\n",
    "            prop_dict[f\"weight_{col.split('_')[1]}\"] = df_row[col] * 4\n",
    "        elif col.startswith('sentiment_'):\n",
    "            prop_dict[f\"sentiment_{col.split('_')[1]}\"] = float(np.nan_to_num(df_row[col]))\n",
    "    callback = gremlin_client.submit_async(f'g.V().hasLabel(\"{df_row[\"party\"]}\").values(\"id\")')\n",
    "    party_id = callback.result().all().result()[0]\n",
    "    add_edge(label='member_discusses', \n",
    "             from_id=party_id, \n",
    "             to_id=f\"topic_{df_row['Topic']}\",\n",
    "             prop_dict=prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_party_topic_grouped.apply(add_party_topic, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding edges among topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_df = topic_df[topic_df['Topic'] >= 0].copy()\n",
    "tt_df['year'] = tt_df['date'].dt.year\n",
    "paragraphs = list(tt_df['paragraph_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = tt_df['year'].unique()\n",
    "start_dict = {'total': 0}\n",
    "for year in years:\n",
    "    start_dict[year] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28047/28047 [01:21<00:00, 344.69it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_combo_dict = {}\n",
    "for paragraph in tqdm(paragraphs, ncols=100):\n",
    "    df_para = tt_df[tt_df['paragraph_id'] == paragraph].groupby(['Topic', 'year'], as_index=False)['Probability'].max().sort_values(by='Topic', ignore_index=True)\n",
    "    if len(df_para.index) > 1:\n",
    "        for a, b in combinations(df_para.index, 2):\n",
    "            topic_combo = (int(df_para.loc[a]['Topic']), int(df_para.loc[b]['Topic']))\n",
    "            if topic_combo not in topic_combo_dict:\n",
    "                topic_combo_dict[topic_combo] = start_dict.copy()\n",
    "            topic_combo_dict[topic_combo][df_para.loc[a]['year']] += df_para.loc[a]['Probability'] * df_para.loc[b]['Probability']\n",
    "            topic_combo_dict[topic_combo]['total'] += df_para.loc[a]['Probability'] * df_para.loc[b]['Probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3456/3456 [00:44<00:00, 78.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for topic_combo, year_dict in tqdm(topic_combo_dict.items(), ncols=100):\n",
    "    prop_dict = {}\n",
    "    for key, value in year_dict.items():\n",
    "        prop_dict[f\"weight_{key}\"] = float(value)\n",
    "    add_edge(label='discussed_together', \n",
    "             from_id=f\"topic_{topic_combo[0]}\",\n",
    "             to_id=f\"topic_{topic_combo[1]}\",\n",
    "             prop_dict=prop_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
