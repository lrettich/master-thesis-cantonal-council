{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gremlinpython in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (3.6.2)\n",
            "Requirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from gremlinpython) (3.8.1)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.6.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from gremlinpython) (0.6.1)\n",
            "Requirement already satisfied: nest-asyncio in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from gremlinpython) (1.5.6)\n",
            "Requirement already satisfied: aenum<4.0.0,>=1.4.5 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from gremlinpython) (3.1.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython) (1.8.2)\n",
            "Requirement already satisfied: six in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from isodate<1.0.0,>=0.6.0->gremlinpython) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp<=3.8.1,>=3.8.0->gremlinpython) (3.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: bokeh in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (3.1.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (2023.2.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (6.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (9.4.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (6.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (23.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (1.22.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (3.1.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from bokeh) (1.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/leorettich/.pyenv/versions/3.10/envs/MA_BERTopic/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->bokeh) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gremlinpython\n",
        "%pip install bokeh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# General imports\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from statistics import mean\n",
        "import itertools\n",
        "\n",
        "# Graph related imports\n",
        "import nest_asyncio\n",
        "from gremlin_python.driver import client, serializer\n",
        "import networkx as nx\n",
        "\n",
        "# Bokeh imports\n",
        "from bokeh.plotting import figure, from_networkx\n",
        "from bokeh.models import Range1d, Circle, MultiLine, ColumnDataSource, LabelSet, NodesAndLinkedEdges\n",
        "from bokeh.io import save\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.palettes import Spectral8"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Establish gremlin connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Necessary to avoid \"RuntimeError: Cannot run the event loop while another loop is running\"\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "gremlin_client = client.Client('wss://leomathesis-cosmos-gremlin.gremlin.cosmos.azure.com:443/', 'g',\n",
        "                               username=\"/dbs/mathesisleo-database/colls/year-graph-2010\",\n",
        "                               password=\"<<password>>\",\n",
        "                               message_serializer=serializer.GraphSONSerializersV2d0()\n",
        "                              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_selected_property_names(prefix, e, start_year=None, end_year=None, total=False):\n",
        "    assert(bool(start_year or end_year) ^ total)\n",
        "    selected_property_names = []\n",
        "    for prop in e['properties'].keys():\n",
        "        if prop.startswith(prefix):\n",
        "            if total:\n",
        "                if prop.endswith('_total'):\n",
        "                    selected_property_names.append(prop)\n",
        "            else:\n",
        "                suffix = prop.split(\"_\")[1]\n",
        "                if suffix.isnumeric():\n",
        "                    year = int(suffix)\n",
        "                    if (start_year is None or start_year <= year) and (end_year is None or end_year >= year):\n",
        "                        selected_property_names.append(prop)\n",
        "    return selected_property_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_add_to_list(target_list, result):\n",
        "    results = result\n",
        "    for element in results:\n",
        "        for list_entry in target_list:\n",
        "            if list_entry['id'] == element['id']:\n",
        "                break\n",
        "        else:\n",
        "            target_list.append(element)\n",
        "    return target_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_year_relevant(start_year, end_year, valid_from, valid_to):\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        if (valid_from is None or year >= valid_from) and (valid_to is None or year <= valid_to):\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_string_date(string_date):\n",
        "    if len(string_date) > 4 and string_date[:4].isnumeric():\n",
        "        return int(string_date[:4])\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_weight_averages(e_list, start_year=None, end_year=None, total=False):\n",
        "    assert(bool(start_year or end_year) ^ total)\n",
        "    weight_list_dict = {'discussed_together': [],\n",
        "                        'member_discusses': [],\n",
        "                        'discusses': []}\n",
        "    for e in e_list:\n",
        "        if e['label'] in weight_list_dict.keys():\n",
        "            weight = 0\n",
        "            for weight_prop in get_selected_property_names('weight', e, start_year, end_year, total):\n",
        "                weight += e['properties'][weight_prop]\n",
        "            weight_list_dict[e['label']].append(weight)\n",
        "    for key, value in weight_list_dict.items():\n",
        "        if len(value) > 0:\n",
        "            weight_list_dict[key] = mean(value)\n",
        "    return weight_list_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def s_hash(x):\n",
        "    return hash(x) % 10**10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to collect data from gremlin queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_graph(topic_list, \n",
        "                neighbor_search_types=[], \n",
        "                weight_treshold={}, \n",
        "                start_year=None, \n",
        "                end_year=None, \n",
        "                total=False, \n",
        "                include_polit_parties=False, \n",
        "                all_edges=False,\n",
        "                edges_among_selection=False):\n",
        "    assert(bool(start_year or end_year) ^ total)\n",
        "    assert(len(topic_list) >= 1)\n",
        "    if include_polit_parties:\n",
        "        assert('discusses' in neighbor_search_types)\n",
        "    v_list = []\n",
        "    e_list = []\n",
        "    for topic in topic_list:\n",
        "        callback = gremlin_client.submit_async(f\"g.V('{topic}')\")\n",
        "        v_list = safe_add_to_list(v_list, callback.result().all().result())\n",
        "        for neighbor_search_type in neighbor_search_types:\n",
        "            if total:\n",
        "                callback = gremlin_client.submit_async(f\"g.V('{topic}').bothE().hasLabel('{neighbor_search_type}').has('weight_total', gt({weight_treshold[neighbor_search_type]})).otherV()\")\n",
        "                v_list = safe_add_to_list(v_list, callback.result().all().result())\n",
        "            else:\n",
        "                callback = gremlin_client.submit_async(f\"g.V('{topic}').bothE().hasLabel('{neighbor_search_type}').has('weight_total', gt({weight_treshold[neighbor_search_type]}))\")\n",
        "                results = callback.result().all().result()\n",
        "                for e in results:\n",
        "                    weight = 0\n",
        "                    for prop in get_selected_property_names('weight', e, start_year, end_year):\n",
        "                        weight += e['properties'][prop]\n",
        "                    if weight >= weight_treshold[neighbor_search_type]:\n",
        "                        if e['inV'] == topic:\n",
        "                            new_v = e['outV']\n",
        "                        else:\n",
        "                            new_v = e['inV']\n",
        "                        callback = gremlin_client.submit_async(f\"g.V('{new_v}')\")\n",
        "                        v_list = safe_add_to_list(v_list, callback.result().all().result())                   \n",
        "            callback = gremlin_client.submit_async(f\"g.V('{topic}').bothE().hasLabel('{neighbor_search_type}').has('weight_total', gt({weight_treshold[neighbor_search_type]}))\")\n",
        "            if total:\n",
        "                e_list = safe_add_to_list(e_list, callback.result().all().result())\n",
        "            else:\n",
        "                results = callback.result().all().result()\n",
        "                for e in results:\n",
        "                    weight = 0\n",
        "                    for prop in get_selected_property_names('weight', e, start_year, end_year):\n",
        "                        weight += e['properties'][prop]\n",
        "                    if weight >= weight_treshold[neighbor_search_type]:\n",
        "                        e_list = safe_add_to_list(e_list, [e])\n",
        "    if include_polit_parties:\n",
        "        for v in v_list:\n",
        "            if v['properties']['type'][0]['value'] == 'politician':\n",
        "                callback = gremlin_client.submit_async(f\"g.V('{v['id']}').outE().hasLabel('is_member_of')\")\n",
        "                results = callback.result().all().result()\n",
        "                for e in results:\n",
        "                    if total or is_year_relevant(start_year, end_year, \n",
        "                                                 transform_string_date(e['properties']['valid_from']), transform_string_date(e['properties']['valid_to'])):\n",
        "                        e_list = safe_add_to_list(e_list, [e])\n",
        "                        callback = gremlin_client.submit_async(f\"g.V('{e['inV']}')\")\n",
        "                        v_list = safe_add_to_list(v_list, callback.result().all().result())  \n",
        "    if all_edges:\n",
        "        all_v_ids = [v['id'] for v in v_list]\n",
        "        for neighbor_search_type in neighbor_search_types:\n",
        "            callback = gremlin_client.submit_async(f\"g.E().hasLabel('{neighbor_search_type}').has('weight_total', gt({weight_treshold[neighbor_search_type]}))\")\n",
        "            all_e = callback.result().all().result()\n",
        "            for e in all_e:\n",
        "                if not total:\n",
        "                    weight = 0\n",
        "                    for prop in get_selected_property_names('weight', e, start_year, end_year):\n",
        "                        weight += e['properties'][prop]\n",
        "                    if weight < weight_treshold[neighbor_search_type]:\n",
        "                        continue\n",
        "                if e['inV'] in all_v_ids and e['outV'] in all_v_ids:\n",
        "                    e_list = safe_add_to_list(e_list, [e])\n",
        "    if edges_among_selection and len(topic_list) > 1:\n",
        "        for selected_topic_comb in itertools.combinations(topic_list, 2):\n",
        "            callback = gremlin_client.submit_async(f\"g.V('{selected_topic_comb[0]}').bothE().where(otherV().hasId('{selected_topic_comb[1]}'))\")\n",
        "            result_e = callback.result().all().result()\n",
        "            for e in result_e:\n",
        "                weight = 0\n",
        "                for prop in get_selected_property_names('weight', e, start_year, end_year):\n",
        "                    weight += e['properties'][prop]\n",
        "                if total or weight >= weight_treshold['discussed_together']:\n",
        "                    e_list = safe_add_to_list(e_list, [e])\n",
        "    return v_list, e_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to create a networkx graph from the gremlin data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_networkx(v_list, e_list, start_year=None, end_year=None, total=False):\n",
        "    assert(bool(start_year or end_year) ^ total)\n",
        "    G = nx.Graph()\n",
        "    for v in v_list:\n",
        "        G.add_node(s_hash(v['id']), label=v['label'], type=v['properties']['type'][0]['value'], type_color=type_colors[v['properties']['type'][0]['value']])   \n",
        "    weight_averages = get_weight_averages(e_list, start_year, end_year, total)\n",
        "    for e in e_list:\n",
        "        weight = 3\n",
        "        sentiment = 0\n",
        "        if e['label'] in ('discussed_together', 'member_discusses', 'discusses'):\n",
        "            weight = 0\n",
        "            for weight_prop in get_selected_property_names('weight', e, start_year, end_year, total):\n",
        "                weight += e['properties'][weight_prop]\n",
        "            weight = (weight / weight_averages[e['label']]) * 5\n",
        "        if e['label'] in ('member_discusses', 'discusses'):\n",
        "            sentiments = []\n",
        "            for sent_prop in get_selected_property_names('sentiment', e, start_year, end_year, total):\n",
        "                sentiments.append(e['properties'][sent_prop])\n",
        "            sentiment = mean(sentiments)\n",
        "        G.add_edge(s_hash(e['outV']), s_hash(e['inV']), sentiment=sentiment, weight=weight)  \n",
        "    return G"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the bokeh visualization from the networkx graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "type_colors = {'politician': Spectral8[0],\n",
        "               'party': Spectral8[1],\n",
        "               'topic': Spectral8[2]}\n",
        "\n",
        "colors = [\"red\", \"grey\", \"green\"]\n",
        "cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"mycmap\", colors)\n",
        "palette = [matplotlib.colors.rgb2hex(c) for c in cmap1(np.linspace(0.1, 0.9, 192))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_bokeh(G, file_name=\"bokeh_2010.html\"):\n",
        "    hover_tooltips = []\n",
        "    plot = figure(tooltips=hover_tooltips,\n",
        "                tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
        "                x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), width=1500, height=1000)\n",
        "    plot.grid.visible = False\n",
        "    plot.axis.visible = False\n",
        "    network_graph = from_networkx(G, nx.spring_layout, scale=10, center=(0, 0))\n",
        "    network_graph.node_renderer.glyph = Circle(size=15, fill_color='type_color')\n",
        "    network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width='weight', line_color=linear_cmap('sentiment', palette, -0.4, 0.4))\n",
        "\n",
        "    network_graph.node_renderer.hover_glyph = Circle(size=15, fill_color='type_color', line_width=2)\n",
        "    network_graph.node_renderer.selection_glyph = Circle(size=15, fill_color='type_color', line_width=2)\n",
        "    network_graph.edge_renderer.selection_glyph = MultiLine(line_alpha=1, line_width='weight', line_color=linear_cmap('sentiment', palette, -0.4, 0.4))\n",
        "    network_graph.edge_renderer.hover_glyph = MultiLine(line_alpha=1, line_width='weight', line_color=linear_cmap('sentiment', palette, -0.4, 0.4))\n",
        "\n",
        "    plot.renderers.append(network_graph)\n",
        "\n",
        "    network_graph.selection_policy = NodesAndLinkedEdges()\n",
        "    network_graph.inspection_policy = NodesAndLinkedEdges()\n",
        "\n",
        "    #Add Labels\n",
        "    x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
        "    node_labels = list(nx.get_node_attributes(G, 'label').values())\n",
        "    source = ColumnDataSource({'x': x, 'y': y, 'name': [node_labels[i] for i in range(len(x))]})\n",
        "    labels = LabelSet(x='x', y='y', text='name', source=source, background_fill_color='white', text_font_size='15px', background_fill_alpha=.7)\n",
        "    plot.renderers.append(labels)\n",
        "\n",
        "    save(plot, filename=file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Execute it!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most Frequent Topics since 2010 and the Relations among them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=[],\n",
        "                             weight_treshold={'discussed_together': 17.5},                             \n",
        "                             start_year=2010, \n",
        "                             end_year=2023, \n",
        "                             include_polit_parties=False,\n",
        "                             total=False,\n",
        "                             all_edges=True,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ZKB and connected topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_6'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=['discussed_together'],\n",
        "                             weight_treshold={'discussed_together': 6.5},                             \n",
        "                             start_year=2010, \n",
        "                             end_year=2023, \n",
        "                             include_polit_parties=False,\n",
        "                             total=False,\n",
        "                             all_edges=False,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ZKb connected to politicians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_6'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=['discusses'],\n",
        "                             weight_treshold={'discusses': 25},                             \n",
        "                             start_year=2022, \n",
        "                             end_year=2022, \n",
        "                             include_polit_parties=True,\n",
        "                             total=False,\n",
        "                             all_edges=False,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "General topics and politicians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=['discusses'],\n",
        "                             weight_treshold={'discusses': 150, 'discussed_together': 1},                             \n",
        "                             start_year=2022, \n",
        "                             end_year=2022, \n",
        "                             include_polit_parties=False,\n",
        "                             total=False,\n",
        "                             all_edges=True,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ZKB conected to parties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_6'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=['member_discusses'],\n",
        "                             weight_treshold={'member_discusses': 100},                             \n",
        "                             start_year=2010, \n",
        "                             end_year=2023, \n",
        "                             include_polit_parties=False,\n",
        "                             total=False,\n",
        "                             all_edges=False,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show abilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
            "  save(plot, filename=file_name)\n",
            "/var/folders/qd/jv7j97lx1tgfwwmrwfd0r62h0000gn/T/ipykernel_7491/234655644.py:29: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
            "  save(plot, filename=file_name)\n"
          ]
        }
      ],
      "source": [
        "v_list, e_list = query_graph(topic_list=['topic_6', 'topic_8', 'topic_12'],\n",
        "                             #neighbor_search_types=['discussed_together', 'discusses', 'member_discusses'],\n",
        "                             #weight_treshold={'discussed_together': 1, 'discusses': 100, 'member_discusses': 100},\n",
        "                             neighbor_search_types=['discusses'],\n",
        "                             weight_treshold={'discussed_together': 3, 'discusses': 150},                             \n",
        "                             start_year=2020, \n",
        "                             end_year=2023, \n",
        "                             include_polit_parties=False,\n",
        "                             total=False,\n",
        "                             all_edges=True,\n",
        "                             edges_among_selection=True)\n",
        "G = create_networkx(v_list=v_list, e_list=e_list, total=True)\n",
        "save_bokeh(G, \"bokeh.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
